# Skill: Assessment Rubric Design

## Purpose
Create clear, objective rubrics that define success criteria and enable consistent, fair evaluation of learner work.

## Responsibility
Design rubrics that communicate expectations, guide learner effort, and enable reliable assessment of complex skills and projects.

## When to Use
- Evaluating projects and assignments
- Assessing capstone work
- Grading code submissions
- Evaluating presentations
- Measuring skill mastery

## Core Capabilities

### 1. Criteria Definition
- Identify assessment dimensions
- Define performance levels
- Establish clear descriptors
- Set measurable standards
- Align with learning outcomes

### 2. Level Differentiation
- Distinguish performance levels
- Create clear boundaries
- Avoid overlapping criteria
- Enable objective scoring
- Support growth mindset

### 3. Descriptor Clarity
- Write specific, observable criteria
- Avoid vague language
- Provide concrete examples
- Enable self-assessment
- Support peer review

### 4. Weighting Strategy
- Assign appropriate weights
- Reflect importance
- Balance dimensions
- Enable partial credit
- Support learning priorities

### 5. Feedback Integration
- Enable constructive feedback
- Identify strengths
- Highlight growth areas
- Guide improvement
- Celebrate achievement

## Rubric Template

```markdown
# Rubric: [Assignment/Project Name]

## Total Points: [X]

## Criteria and Scoring

### Criterion 1: [Name] ([X] points)

**Weight**: [X]% of total grade

**Learning Outcome**: [LO-X.X]

| Level | Score | Description | Indicators |
|-------|-------|-------------|------------|
| **Exemplary** | [X-Y] | [Clear description of exceptional work] | • [Specific indicator 1]<br>• [Specific indicator 2]<br>• [Specific indicator 3] |
| **Proficient** | [X-Y] | [Clear description of meeting expectations] | • [Specific indicator 1]<br>• [Specific indicator 2]<br>• [Specific indicator 3] |
| **Developing** | [X-Y] | [Clear description of partial achievement] | • [Specific indicator 1]<br>• [Specific indicator 2]<br>• [Specific indicator 3] |
| **Beginning** | [X-Y] | [Clear description of minimal achievement] | • [Specific indicator 1]<br>• [Specific indicator 2]<br>• [Specific indicator 3] |

---

### Criterion 2: [Name] ([X] points)
[Repeat structure]

---

## Scoring Summary

| Criterion | Weight | Your Score | Comments |
|-----------|--------|------------|----------|
| [Criterion 1] | [X]% | ___/[X] | |
| [Criterion 2] | [X]% | ___/[X] | |
| [Criterion 3] | [X]% | ___/[X] | |
| **Total** | 100% | ___/[X] | |

## Grade Scale
- A (90-100%): Exemplary work
- B (80-89%): Proficient work
- C (70-79%): Developing work
- D (60-69%): Beginning work
- F (<60%): Incomplete work

## Feedback Template

**Strengths**:
- [What was done well]

**Areas for Growth**:
- [What could be improved]

**Next Steps**:
- [Specific actions to improve]
```

## Example Rubrics

### Example 1: Code Assignment Rubric

```markdown
# Rubric: ROS 2 Publisher Implementation

## Total Points: 100

### 1. Functionality (40 points)

**Learning Outcome**: LO-3.2 (Implement a ROS 2 publisher)

| Level | Score | Description | Indicators |
|-------|-------|-------------|------------|
| **Exemplary** | 36-40 | Publisher works flawlessly with all requirements met and additional features | • Publishes at correct rate<br>• Message format correct<br>• Handles edge cases<br>• Includes error handling<br>• Additional features implemented |
| **Proficient** | 32-35 | Publisher works correctly with all core requirements met | • Publishes at correct rate<br>• Message format correct<br>• Basic functionality complete<br>• No crashes or errors |
| **Developing** | 24-31 | Publisher works but has minor issues or missing features | • Publishes but rate may be incorrect<br>• Message format mostly correct<br>• Some functionality missing<br>• Occasional errors |
| **Beginning** | 0-23 | Publisher does not work or has major issues | • Does not publish correctly<br>• Message format incorrect<br>• Major functionality missing<br>• Frequent crashes |

### 2. Code Quality (30 points)

**Learning Outcome**: Professional coding practices

| Level | Score | Description | Indicators |
|-------|-------|-------------|------------|
| **Exemplary** | 27-30 | Code is exceptionally clean, well-organized, and follows best practices | • Clear variable names<br>• Comprehensive comments<br>• Proper error handling<br>• Follows PEP 8 style<br>• Modular design |
| **Proficient** | 24-26 | Code is clean and follows good practices | • Descriptive variable names<br>• Adequate comments<br>• Basic error handling<br>• Mostly follows style guide |
| **Developing** | 18-23 | Code works but has style or organization issues | • Some unclear names<br>• Minimal comments<br>• Limited error handling<br>• Style inconsistencies |
| **Beginning** | 0-17 | Code is difficult to read or poorly organized | • Unclear variable names<br>• No comments<br>• No error handling<br>• Does not follow style guide |

### 3. Documentation (20 points)

**Learning Outcome**: Technical communication

| Level | Score | Description | Indicators |
|-------|-------|-------------|------------|
| **Exemplary** | 18-20 | Documentation is comprehensive and professional | • Clear README with setup<br>• Code well-commented<br>• Usage examples provided<br>• Architecture explained<br>• Troubleshooting included |
| **Proficient** | 16-17 | Documentation is complete and clear | • README with setup<br>• Key code commented<br>• Basic usage explained<br>• Main concepts documented |
| **Developing** | 12-15 | Documentation is present but incomplete | • Basic README<br>• Some comments<br>• Minimal usage info<br>• Missing key details |
| **Beginning** | 0-11 | Documentation is missing or inadequate | • No README or very basic<br>• Few or no comments<br>• No usage information<br>• Unclear how to use |

### 4. Testing (10 points)

**Learning Outcome**: Verification and validation

| Level | Score | Description | Indicators |
|-------|-------|-------------|------------|
| **Exemplary** | 9-10 | Comprehensive testing with multiple scenarios | • All features tested<br>• Edge cases covered<br>• Test results documented<br>• Automated tests included |
| **Proficient** | 8 | Core functionality tested adequately | • Main features tested<br>• Basic scenarios covered<br>• Test results shown |
| **Developing** | 6-7 | Limited testing performed | • Some features tested<br>• Basic verification only<br>• Incomplete results |
| **Beginning** | 0-5 | Minimal or no testing | • Little to no testing<br>• No verification<br>• No test documentation |

## Scoring Summary

| Criterion | Weight | Points | Your Score |
|-----------|--------|--------|------------|
| Functionality | 40% | 40 | ___/40 |
| Code Quality | 30% | 30 | ___/30 |
| Documentation | 20% | 20 | ___/20 |
| Testing | 10% | 10 | ___/10 |
| **Total** | 100% | 100 | ___/100 |
```

### Example 2: Capstone Project Rubric

```markdown
# Rubric: Autonomous Robot Capstone Project

## Total Points: 200

### 1. Technical Implementation (80 points)

#### 1.1 System Architecture (20 points)

| Level | Score | Description |
|-------|-------|-------------|
| **Exemplary** | 18-20 | Well-designed, modular architecture with clear separation of concerns |
| **Proficient** | 16-17 | Functional architecture with reasonable organization |
| **Developing** | 12-15 | Basic architecture with some organizational issues |
| **Beginning** | 0-11 | Poor architecture or monolithic design |

#### 1.2 Core Functionality (30 points)

| Level | Score | Description |
|-------|-------|-------------|
| **Exemplary** | 27-30 | All required features work flawlessly, plus additional enhancements |
| **Proficient** | 24-26 | All required features work correctly |
| **Developing** | 18-23 | Most features work, some issues present |
| **Beginning** | 0-17 | Many features missing or not working |

#### 1.3 Integration (15 points)

| Level | Score | Description |
|-------|-------|-------------|
| **Exemplary** | 14-15 | Seamless integration of all components |
| **Proficient** | 12-13 | Components work together well |
| **Developing** | 9-11 | Integration has some issues |
| **Beginning** | 0-8 | Poor integration or components don't work together |

#### 1.4 Robustness (15 points)

| Level | Score | Description |
|-------|-------|-------------|
| **Exemplary** | 14-15 | Handles errors gracefully, recovers from failures |
| **Proficient** | 12-13 | Basic error handling present |
| **Developing** | 9-11 | Limited error handling |
| **Beginning** | 0-8 | No error handling, crashes frequently |

### 2. Code Quality (40 points)

#### 2.1 Organization (15 points)
[Similar structure]

#### 2.2 Style and Conventions (10 points)
[Similar structure]

#### 2.3 Comments and Documentation (15 points)
[Similar structure]

### 3. Demonstration (40 points)

#### 3.1 Video Quality (10 points)
[Similar structure]

#### 3.2 Feature Demonstration (20 points)
[Similar structure]

#### 3.3 Explanation (10 points)
[Similar structure]

### 4. Written Report (40 points)

#### 4.1 Technical Description (15 points)
[Similar structure]

#### 4.2 Design Decisions (10 points)
[Similar structure]

#### 4.3 Challenges and Solutions (10 points)
[Similar structure]

#### 4.4 Reflection (5 points)
[Similar structure]

## Detailed Scoring

[Complete breakdown with all criteria]

## Final Grade

| Category | Points | Your Score | Percentage |
|----------|--------|------------|------------|
| Technical Implementation | 80 | ___/80 | ___% |
| Code Quality | 40 | ___/40 | ___% |
| Demonstration | 40 | ___/40 | ___% |
| Written Report | 40 | ___/40 | ___% |
| **Total** | 200 | ___/200 | ___% |

**Letter Grade**: ___

## Feedback

**Outstanding Aspects**:
- [Specific strengths]

**Strong Performance**:
- [What was done well]

**Areas for Improvement**:
- [Constructive feedback]

**Recommendations**:
- [Specific suggestions for growth]
```

## Rubric Design Principles

### Principle 1: Specificity
```markdown
<!-- Vague (BAD) -->
Code is good quality

<!-- Specific (GOOD) -->
Code uses descriptive variable names, includes comments explaining complex logic, follows PEP 8 style guide, and includes error handling for edge cases
```

### Principle 2: Observable Criteria
```markdown
<!-- Not observable (BAD) -->
Student understands ROS 2 concepts

<!-- Observable (GOOD) -->
Student correctly implements publisher-subscriber communication, explains the decoupling benefit in documentation, and demonstrates understanding through working code
```

### Principle 3: Clear Differentiation
```markdown
<!-- Overlapping (BAD) -->
Proficient: Code is well-written
Exemplary: Code is very well-written

<!-- Clear differentiation (GOOD) -->
Proficient: Code follows style guide, has descriptive names, includes basic comments
Exemplary: Code follows style guide, has descriptive names, includes comprehensive comments, demonstrates advanced patterns, includes error handling
```

## Quality Standards

### Clarity
- Criteria are specific and observable
- Performance levels are clearly differentiated
- Language is unambiguous
- Examples provided where helpful
- Self-assessment enabled

### Fairness
- Criteria are objective
- Bias is minimized
- Multiple paths to success
- Partial credit possible
- Transparent expectations

### Alignment
- Maps to learning outcomes
- Reflects course priorities
- Assesses what was taught
- Appropriate difficulty
- Authentic to domain

### Usability
- Easy to understand
- Quick to apply
- Consistent scoring
- Enables feedback
- Supports improvement

## Integration Points
- Implements learning outcomes
- Guides assessment design
- Enables fair evaluation
- Supports feedback
- Measures mastery
